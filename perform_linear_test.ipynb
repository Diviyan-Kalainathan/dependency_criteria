{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook perform_linear_test.ipynb to script\n",
      "[NbConvertApp] Writing 7472 bytes to perform_linear_test.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script perform_linear_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from random import shuffle\n",
    "from multiprocessing import Pool,Array\n",
    "import sys\n",
    "import json\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "njobs=40\n",
    "from joblib import Memory, Parallel, delayed\n",
    "mem = Memory('/tmp/joblib/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_variable(var1):   # bin with normalization\n",
    "    \n",
    "    var1=np.array(var1).astype(np.float)\n",
    "    \n",
    "    if abs(np.std(var1))>0.01:\n",
    "        var1 = (var1 - np.mean(var1))/np.std(var1)\n",
    "    else:\n",
    "        var1 = (var1 - np.mean(var1))\n",
    "    val1 = np.digitize(var1, np.histogram(var1, bins='fd')[1])\n",
    "    #print(type(val1))\n",
    "    #print((val1).shape())\n",
    "    return val1\n",
    "\n",
    "def p_val_mi(x,y):\n",
    "    count=0.0\n",
    "    iterations=10000\n",
    "    score=metrics.adjusted_mutual_info_score(x,y)\n",
    "    for i in range(iterations):\n",
    "        shuffle(x)\n",
    "        shuffle(y)\n",
    "        if metrics.adjusted_mutual_info_score(x,y)>=score:\n",
    "            count+=1.0\n",
    "    return count/iterations\n",
    "        \n",
    "pearsonc=lambda x,y : stats.pearsonr(np.array(x),np.array(y))[0]\n",
    "p_val_test1=lambda x,y :stats.pearsonr(np.array(x),np.array(y))[1]\n",
    "\n",
    "ajd_mi_bin=lambda x,y : metrics.adjusted_mutual_info_score(bin_variable(x),bin_variable(y))\n",
    "p_val_test2= lambda x,y : p_val_mi(bin_variable(x),bin_variable(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Evaluating p-distribution for p-value computation\n",
    "num_samples_estimation=100000\n",
    "sig_to_noise_rate=[j*0.1 for j in range(21)] #0, 0.1 ,...,0.9, 1,...2\n",
    "sig_to_noise_rate[0]=0.0001\n",
    "num_points=[k*10 for k in range(1,16)]#10,20,30,...150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points : 10\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_MI...\n",
      "estimate_null_d_MI()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_MI...\n",
      "estimate_null_d_MI()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_MI...\n",
      "estimate_null_d_MI()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_MI...\n",
      "estimate_null_d_MI()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_MI...\n",
      "estimate_null_d_MI()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_MI...\n",
      "estimate_null_d_MI()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_MI...\n",
      "estimate_null_d_MI()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________estimate_null_d_MI - 0.0s, 0.0min\n",
      "_______________________________________________estimate_null_d_MI - 0.0s, 0.0min\n",
      "_______________________________________________estimate_null_d_MI - 0.0s, 0.0min\n",
      "_______________________________________________estimate_null_d_MI - 0.0s, 0.0min\n",
      "_______________________________________________estimate_null_d_MI - 0.0s, 0.0min\n",
      "_______________________________________________estimate_null_d_MI - 0.1s, 0.0min\n",
      "_______________________________________________estimate_null_d_MI - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 4182 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=7)]: Done 21642 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=7)]: Done 46086 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=7)]: Done 77514 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=7)]: Done 100000 out of 100000 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[MemorizedFunc(func=<function estimate_null_d_pearson at 0x7f4907337848>, cachedir='/tmp/joblib/joblib')]: Exception while loading results for (args=(), kwargs={})\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 444, in _cached_call\n",
      "    verbose=self._verbose)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 133, in _load_output\n",
      "    return numpy_pickle.load(filename, mmap_mode=mmap_mode)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/numpy_pickle.py\", line 575, in load\n",
      "    obj = _unpickle(fobj, filename, mmap_mode)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/numpy_pickle.py\", line 507, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/pickle.py\", line 864, in load\n",
      "    dispatch[key](self)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/pickle.py\", line 886, in load_eof\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "\n",
      "\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[MemorizedFunc(func=<function estimate_null_d_pearson at 0x7f4907337848>, cachedir='/tmp/joblib/joblib')]: Exception while loading results for (args=(), kwargs={})\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 444, in _cached_call\n",
      "    verbose=self._verbose)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 133, in _load_output\n",
      "    return numpy_pickle.load(filename, mmap_mode=mmap_mode)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/numpy_pickle.py\", line 575, in load\n",
      "    obj = _unpickle(fobj, filename, mmap_mode)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/numpy_pickle.py\", line 507, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/pickle.py\", line 864, in load\n",
      "    dispatch[key](self)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/pickle.py\", line 886, in load_eof\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[MemorizedFunc(func=<function estimate_null_d_pearson at 0x7f4907337848>, cachedir='/tmp/joblib/joblib')]: Exception while loading results for (args=(), kwargs={})\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 444, in _cached_call\n",
      "    verbose=self._verbose)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 132, in _load_output\n",
      "    \"File %s does not exist\" % filename)\n",
      "KeyError: 'Non-existing cache value (may have been cleared).\\nFile /tmp/joblib/joblib/__main__--home-diviyan-phd-dependency_criteria-__ipython-input__/estimate_null_d_pearson/08d116bec02752b026577cdc25ee6ebe/output.pkl does not exist'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "\n",
      "\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[MemorizedFunc(func=<function estimate_null_d_pearson at 0x7f4907337848>, cachedir='/tmp/joblib/joblib')]: Exception while loading results for (args=(), kwargs={})\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 444, in _cached_call\n",
      "    verbose=self._verbose)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 133, in _load_output\n",
      "    return numpy_pickle.load(filename, mmap_mode=mmap_mode)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/numpy_pickle.py\", line 575, in load\n",
      "    obj = _unpickle(fobj, filename, mmap_mode)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/numpy_pickle.py\", line 507, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/pickle.py\", line 864, in load\n",
      "    dispatch[key](self)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/pickle.py\", line 886, in load_eof\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "WARNING:root:[MemorizedFunc(func=<function estimate_null_d_pearson at 0x7f4907337848>, cachedir='/tmp/joblib/joblib')]: Exception while loading results for (args=(), kwargs={})\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 444, in _cached_call\n",
      "    verbose=self._verbose)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/memory.py\", line 133, in _load_output\n",
      "    return numpy_pickle.load(filename, mmap_mode=mmap_mode)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/numpy_pickle.py\", line 575, in load\n",
      "    obj = _unpickle(fobj, filename, mmap_mode)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/numpy_pickle.py\", line 507, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/pickle.py\", line 864, in load\n",
      "    dispatch[key](self)\n",
      "  File \"/home/diviyan/miniconda2/envs/py27/lib/python2.7/pickle.py\", line 886, in load_eof\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "\n",
      "\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done 3942 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=7)]: Done 14742 tasks      | elapsed:    4.0s\n",
      "WARNING:root:[MemorizedFunc(func=<function estimate_null_d_pearson at 0x7f4907337848>, cachedir='/tmp/joblib/joblib')]: Clearing cache /tmp/joblib/joblib/__main__--home-diviyan-phd-dependency_criteria-__ipython-input__/estimate_null_d_pearson\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--home-diviyan-phd-dependency_criteria-__ipython-input__.estimate_null_d_pearson...\n",
      "estimate_null_d_pearson()\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n",
      "__________________________________________estimate_null_d_pearson - 0.0s, 0.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6aebd856482a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mv_mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multiprocessing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchc_nd_MI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples_estimation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mvalues_MI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mv_pear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multiprocessing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchc_nd_pear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples_estimation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mvalues_pear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_pear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     '''values_pear.append([])\n",
      "\u001b[0;32m/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diviyan/miniconda2/envs/py27/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def estimate_null_d_pearson(k):\n",
    "    x = np.random.normal(0,1,k)\n",
    "    y = np.random.normal(0,1,k)\n",
    "    return pearsonc(x,y)\n",
    "    \n",
    "def estimate_null_d_MI(k):\n",
    "    x = np.random.normal(0,1,k)\n",
    "    y = np.random.normal(0,1,k)\n",
    "    return ajd_mi_bin(x,y)\n",
    "\n",
    "#chc_nd_pear = mem.cache(estimate_null_d_pearson)\n",
    "#chc_nd_MI = mem.cache(estimate_null_d_MI)\n",
    "\n",
    "values_pear=[]\n",
    "values_MI=[]\n",
    "# Pearson & MI\n",
    "for idx_k,k in zip(range(len(num_points)),num_points):\n",
    "    print('Number of points : '+str(k))\n",
    "    v_mi=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(delayed(estimate_null_d_MI)(k) for i in range(num_samples_estimation))\n",
    "    values_MI.append(v_mi)\n",
    "    v_pear=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(delayed(estimate_null_d_pearson)(k) for i in range(num_samples_estimation))\n",
    "    values_pear.append(v_pear)\n",
    "    '''values_pear.append([])\n",
    "    values_MI.append([])\n",
    "        for i in range(num_samples_estimation):\n",
    "        #print(i),\n",
    "        x = np.random.normal(0,1,k)\n",
    "        y = np.random.normal(0,1,k)\n",
    "        values_pear[idx_k].append(pearsonc(x,y))\n",
    "        values_MI[idx_k].append(ajd_mi_bin(x,y))'''\n",
    "        \n",
    "    with open('Pearson_samples_'+str(k)+'temp_H0.txt','wb') as outfile:\n",
    "        json.dump(values_pear[idx_k],outfile)\n",
    "        \n",
    "    with open('Adj_MI_bin_samples_'+str(k)+'temp_H0.txt','wb') as outfile:\n",
    "        json.dump(values_MI[idx_k],outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'values_pear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2a785b9ad769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#    values_MI[i]=list(np.sort(values_MI[i],kind='mergesort'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pearson_samples_H0.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues_pear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adj_MI_bin_samples_H0.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'values_pear' is not defined"
     ]
    }
   ],
   "source": [
    "#Save data generated\n",
    "#for i in range(len(values_pear)):\n",
    "#    values_pear[i]=list(np.sort(values_pear[i],kind='mergesort'))\n",
    "#    values_MI[i]=list(np.sort(values_MI[i],kind='mergesort'))\n",
    "with open('Pearson_samples_H2.txt','wb') as outfile:\n",
    "    json.dump(values_pear,outfile)\n",
    "        \n",
    "with open('Adj_MI_bin_samples_H2.txt','wb') as outfile:\n",
    "    json.dump(values_MI,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No JSON object could be decoded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6d980f50f7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pearson_samples_H0.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mvalues_pear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adj_MI_bin_samples_H0.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mvalues_MI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diviyan/miniconda3/envs/py27/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mparse_constant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_constant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_pairs_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_pairs_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         **kw)\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diviyan/miniconda3/envs/py27/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diviyan/miniconda3/envs/py27/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diviyan/miniconda3/envs/py27/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No JSON object could be decoded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No JSON object could be decoded"
     ]
    }
   ],
   "source": [
    "# Analyse density curves?\n",
    "try:\n",
    "    values_pear\n",
    "except NameError:\n",
    "    with open('Pearson_samples_H2.txt','rb') as input1:\n",
    "        values_pear=json.load(input1)\n",
    "    with open('Adj_MI_bin_samples_H2.txt','rb') as input2:\n",
    "        values_MI=json.load(input2)\n",
    "for i,nb_pts in zip(range(len(num_points)),num_points): \n",
    "    data = np.vstack([values_pear[i],values_MI[i]]).T\n",
    "    plt.hist(data,bins=21,label=['Pearson correlation','Adjusted Mutual info score + fd binning'])\n",
    "    plt.title('Histogram of independancy criteria distribution depending for '+str(nb_pts) +' points')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig('figures/histo_distrib_'+str(nb_pts)+'_pts.png')\n",
    "    #plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Sig/Noise : 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done 3000 out of 3000 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'values_MI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-79e6383c210a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         tmp_MI=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(\n\u001b[1;32m     40\u001b[0m             delayed(estimate_l_MI)(k,j) for i in range(num_samples_experiment))\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mvalues_MI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_MI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_MI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         tmp_pear=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'values_MI' is not defined"
     ]
    }
   ],
   "source": [
    "# Computation of pear & MI on linear data\n",
    "def estimate_l_pearson(k,j):\n",
    "    noise=np.random.normal(0,j,k)\n",
    "    x=np.random.normal(0,1,k)\n",
    "    y=[sum(s) for s in zip(x, noise)]\n",
    "    return pearsonc(x,y)\n",
    "    \n",
    "def estimate_l_MI(k,j):\n",
    "    noise=np.random.normal(0,j,k)\n",
    "    x=np.random.normal(0,1,k)\n",
    "    y=[sum(s) for s in zip(x, noise)]\n",
    "    return ajd_mi_bin(x,y)\n",
    "\n",
    "#chc_l_pear = mem.cache(estimate_l_pearson)\n",
    "#chc_l_MI = mem.cache(estimate_l_MI)\n",
    "\n",
    "num_samples_experiment=10000\n",
    "result_pear=[]\n",
    "pval_pear=[]\n",
    "result_MI=[]\n",
    "pval_MI=[]\n",
    "\n",
    "for idx_j,j in zip(range(len(sig_to_noise_rate)),sig_to_noise_rate):\n",
    "    result_pear.append([])\n",
    "    print('-Sig/Noise : '+str(j))\n",
    "    #result_anapear.append([])\n",
    "    result_MI.append([]) \n",
    "    pval_pear.append([])\n",
    "    pval_MI.append([])\n",
    "    \n",
    "    for idx_k,k in zip(range(len(num_points)),num_points):\n",
    "        #print('--Number of points : '+str(k))\n",
    "        result_pear[idx_j].append([])\n",
    "        #result_anapear[idx_j].append([])\n",
    "        result_MI[idx_j].append([]) \n",
    "        pval_pear[idx_j].append([])\n",
    "        pval_MI[idx_j].append([])\n",
    "        \n",
    "        tmp_MI=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(\n",
    "            delayed(estimate_l_MI)(k,j) for i in range(num_samples_experiment))\n",
    "        values_MI.append(tmp_MI)\n",
    "        print(tmp_MI)\n",
    "        tmp_pear=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(\n",
    "            delayed(estimate_l_pearson)(k,j) for i in range(num_samples_experiment))\n",
    "        values_pear.append(tmp_pear)\n",
    "        '''for i in range(num_samples_experiment):\n",
    "            #generate the mecanism\n",
    "            #print(j),\n",
    "            #print(k)\n",
    "            noise=np.random.normal(0,j,k)\n",
    "            x=np.random.normal(0,1,k)\n",
    "            y=[sum(s) for s in zip(x, noise)]\n",
    "            #print(x)\n",
    "            #print(y)\n",
    "            pear=pearsonc(x,y)\n",
    "            MI_score=ajd_mi_bin(x,y)\n",
    "            result_pear[idx_j][idx_k].append(pear)\n",
    "            result_MI[idx_j][idx_k].append(MI_score)'''\n",
    "            \n",
    "            \n",
    "'''p_rank_MI=0.0\n",
    "            p_rank_pear=0.0\n",
    "            \n",
    "            for pval in range(len(values_pear[idx_k])):\n",
    "                if values_pear[idx_k][pval]>pear:\n",
    "                    p_rank_pear+=1.0\n",
    "            \n",
    "            for pval in range(len(values_pear[idx_k])):\n",
    "                if values_MI[idx_k][pval]>MI_score:\n",
    "                    p_rank_MI+=1.0\n",
    "            \n",
    "            #while values_pear[idx_k][int(p_rank_pear)]>pear and p_rank_pear>0:\n",
    "            #    p_rank_pear-=1.0\n",
    "            #while values_MI[idx_k][int(p_rank_MI)]>pear and p_rank_MI>0:\n",
    "            #    p_rank_MI-=1.0\n",
    "            \n",
    "            #pval_pear[idx_j][idx_k].append((len(values_pear[idx_k])-p_rank_pear)\n",
    "                                           #/len(values_pear[idx_k]))\n",
    "            #pval_MI[idx_j][idx_k].append((len(values_MI[idx_k])-p_rank_MI)\n",
    "                                           #/len(values_MI[idx_k]))\n",
    "            pval_pear[idx_j][idx_k].append(p_rank_pear/len(values_pear[idx_k]))\n",
    "            # print(p_rank_pear/len(values_pear[idx_k])),\n",
    "            pval_MI[idx_j][idx_k].append(p_rank_MI/len(values_MI[idx_k]))\n",
    "            # print(p_rank_MI/len(values_MI[idx_k]))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_pear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-29d814487c58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pearson_coeff2.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_pear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adj_MI_coeff2.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_pear' is not defined"
     ]
    }
   ],
   "source": [
    "#Save final results\n",
    "'''with open('Pearson_p_values2.txt','wb') as outfile:\n",
    "    json.dump(pval_pear,outfile)\n",
    "        \n",
    "with open('Adj_MI_p_values2.txt','wb') as outfile:\n",
    "    json.dump(pval_MI,outfile)'''\n",
    "\n",
    "with open('Pearson_coeff2.txt','wb') as outfile:\n",
    "    json.dump(result_pear,outfile)\n",
    "        \n",
    "with open('Adj_MI_coeff2.txt','wb') as outfile:\n",
    "    json.dump(result_MI,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_FDR_MI(idx_j,idx_k,MI_score):\n",
    "    #Rank on Null distribution\n",
    "    p_rank_MI   = 0.0\n",
    "    #Rank on alternative distribution\n",
    "    a_rank_MI   = 0.0\n",
    "\n",
    "    for pval in range(len(values_MI[idx_k])):\n",
    "        if values_MI[idx_k][pval]>MI_score:\n",
    "            p_rank_MI+=1.0 \n",
    "\n",
    "    for aval in range(len(result_MI[idx_j][idx_k])):\n",
    "        if result_MI[idx_j][idx_k][aval]>MI_score:\n",
    "            a_rank_MI+=1.0\n",
    "\n",
    "    try: \n",
    "        return p_rank_MI/(p_rank_MI+a_rank_MI)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    \n",
    "def compute_FDR_pear(idx_j,idx_k,pear):\n",
    "    p_rank_pear = 0.0 #Rank on Null distribution\n",
    "    a_rank_pear = 0.0 #Rank on alternative distribution\n",
    "\n",
    "    for pval in range(len(values_pear[idx_k])):\n",
    "        if values_pear[idx_k][pval]>pear:\n",
    "            p_rank_pear+=1.0\n",
    "\n",
    "    for aval in range(len(result_pear[idx_j][idx_k])):\n",
    "        if result_pear[idx_j][idx_k][aval]>pear:\n",
    "            a_rank_pear+=1.0\n",
    "    try:\n",
    "        return p_rank_pear/(p_rank_pear+a_rank_pear)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    #print(p_rank_MI/(p_rank_MI+a_rank_MI)),\n",
    "    #print(pval_MI[idx_j][idx_k][idx_l]*num_samples_estimation/(p_rank_MI+a_rank_MI))\n",
    "#cached_fdr_mi = mem.cache(compute_FDR_MI)\n",
    "#cached_fdr_pear = mem.cache(compute_FDR_pear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done 1000 out of 1000 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=40)]: Done 1000 out of 1000 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=40)]: Done 1000 out of 1000 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=40)]: Done 1000 out of 1000 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=40)]: Done 240 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 1000 out of 1000 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=40)]: Done 1000 out of 1000 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-48dc1b55f97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#FDR_pear[idx_j].append([])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         tmp_mi=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(delayed(compute_FDR_MI)(idx_j,idx_k,MI_score)\n\u001b[0;32m---> 12\u001b[0;31m                                   for MI_score in result_MI[idx_j][idx_k])\n\u001b[0m\u001b[1;32m     13\u001b[0m         tmp_pear=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(delayed(compute_FDR_pear)(idx_j,idx_k,pear)\n\u001b[1;32m     14\u001b[0m                                   for pear in result_pear[idx_j][idx_k])\n",
      "\u001b[0;32m/home/diviyan/miniconda3/envs/py27/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/diviyan/miniconda3/envs/py27/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Compute FDR : \n",
    "try: \n",
    "    pval_MI\n",
    "except NameError:\n",
    "    with open('Pearson_p_values2txt','r') as outfile:\n",
    "        pval_pear=json.load(outfile)\n",
    "        \n",
    "    with open('Adj_MI_p_values2txt','r') as outfile:\n",
    "        pval_MI=json.load(outfile)\n",
    "\n",
    "FDR_MI=[]\n",
    "FDR_pear=[]\n",
    "for idx_j in range(len(sig_to_noise_rate)):\n",
    "    #result_anapear.append([])\n",
    "    FDR_MI.append([]) \n",
    "    FDR_pear.append([])\n",
    "    for idx_k in range(len(num_points)):\n",
    "        #FDR_MI[idx_j].append([]) \n",
    "        #FDR_pear[idx_j].append([])\n",
    "        tmp_mi=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(delayed(compute_FDR_MI)(idx_j,idx_k,MI_score)\n",
    "                                  for MI_score in result_MI[idx_j][idx_k])\n",
    "        tmp_pear=Parallel(n_jobs=njobs,backend=\"multiprocessing\",verbose=1)(delayed(compute_FDR_pear)(idx_j,idx_k,pear)\n",
    "                                  for pear in result_pear[idx_j][idx_k])\n",
    "        FDR_MI.append(tmp_mi)\n",
    "        FDR_pear.append(tmp_pear)\n",
    "        \n",
    "with open('FDR_MI.txt','wb') as outfile:\n",
    "    json.dump(FDR_MI,outfile)\n",
    "        \n",
    "with open('FDR_pear.txt','wb') as outfile:\n",
    "    json.dump(FDR_pear,outfile)\n",
    "'''for idx_l,MI_score,pear in zip(range(len(result_MI[idx_j][idx_k])),\n",
    "                               result_MI[idx_j][idx_k],result_pear[idx_j][idx_k]):\n",
    "                \n",
    "                p_rank_pear = 0.0 #Rank on Null distribution\n",
    "                p_rank_MI   = 0.0\n",
    "                a_rank_pear = 0.0 #Rank on alternative distribution\n",
    "                a_rank_MI   = 0.0\n",
    "                \n",
    "                for pval in range(len(values_pear[idx_k])):\n",
    "                    if values_pear[idx_k][pval]>pear:\n",
    "                        p_rank_pear+=1.0\n",
    "                    if values_MI[idx_k][pval]>MI_score:\n",
    "                        p_rank_MI+=1.0 \n",
    "                        \n",
    "                for aval in range(len(result_pear[idx_j][idx_k])):\n",
    "                    if result_pear[idx_j][idx_k][aval]>pear:\n",
    "                        a_rank_pear+=1.0\n",
    "                    if result_MI[idx_j][idx_k][aval]>MI_score:\n",
    "                        a_rank_MI+=1.0\n",
    "                \n",
    "                FDR_MI[idx_j][idx_k].append(p_rank_MI/(p_rank_MI+a_rank_MI))\n",
    "                FDR_pear[idx_j][idx_k].append(p_rank_pear/(p_rank_pear+a_rank_pear))\n",
    "                \n",
    "                print(p_rank_MI/(p_rank_MI+a_rank_MI)),\n",
    "                print(pval_MI[idx_j][idx_k][idx_l]*num_samples_estimation/(p_rank_MI+a_rank_MI))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"t_t,prob=stats.ttest_ind(pval_pear[len(pval_pear)-1][0],pval_MI[len(pval_pear)-1][0],equal_var=False)\\nprint(t_t,prob)\\n\\nfor i in range(len(pval_pear)-1):\\n    print('Sig/Noise : '+str(i*0.05))\\n    t_t,prob=stats.ttest_ind(pval_pear[i][0],pval_MI[i][0],equal_var=False)\\n    print(means_MI[i,0],std_MI[i,0])\\n    print(means_pear[i,0],std_pear[i,0])\\n    print(t_t,prob)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load final results\n",
    "try: \n",
    "    pval_MI\n",
    "except NameError:\n",
    "    with open('Pearson_p_values.txt','r') as outfile:\n",
    "        pval_pear=json.load(outfile)\n",
    "        \n",
    "    with open('Adj_MI_p_values.txt','r') as outfile:\n",
    "        pval_MI=json.load(outfile)\n",
    "\n",
    "    with open('Pearson_coeff.txt','r') as outfile:\n",
    "        result_pear=json.load(outfile)\n",
    "\n",
    "    with open('Adj_MI_coeff.txt','r') as outfile:\n",
    "        result_MI=json.load(outfile)\n",
    "        \n",
    "'''#Plots\n",
    "reshape_pval_pear=[pval_pear[j][i] for j in range(len(pval_pear)) \n",
    "                   for i in range(len(pval_pear[0]))]\n",
    "\n",
    "reshape_pval_pear=[pval_MI[j][i] for j in range(len(pval_pear)) \n",
    "                   for i in range(len(pval_pear[0]))]\n",
    "all_pts_pval_pear=[np.mean(i) for i in pval_pear]\n",
    "all_pts_pval_MI=[np.mean(i) for i in pval_MI]\n",
    "all_pts_pv_std_pear=[np.std(i) for i in pval_pear]\n",
    "all_pts_pv_std_MI=[np.std(i) for i in pval_MI]\n",
    "\n",
    "means_pear=np.zeros((len(p_val_MI),len(pval_MI[0]))) #noise/sig ratio then Nb points \n",
    "means_MI=np.zeros((len(pval_MI),len(pval_MI[0])))\n",
    "std_pear=np.zeros((len(pval_MI),len(pval_MI[0])))\n",
    "std_MI=np.zeros((len(pval_MI),len(pval_MI[0])))\n",
    "\n",
    "#Matrixes of means \n",
    "for i in range(means_MI.shape[0]):\n",
    "    for j in range(means_MI.shape[1]):\n",
    "        means_MI[i,j]=np.mean(pval_MI[i][j])\n",
    "        means_pear[i,j]=np.mean(pval_pear[i][j])\n",
    "        std_MI[i,j]=np.std(pval_MI[i][j])\n",
    "        std_pear[i,j]=np.std(pval_pear[i][j])\n",
    "for i in range(0,4): #Nb points\n",
    "    #rint((sig_to_noise_rate))\n",
    "    #rint(list(means_MI[:,i]))\n",
    "    plt.errorbar(sig_to_noise_rate,list(means_MI[:,i]),yerr=std_MI[:,i],label=str((i+1)*10)+' pts')\n",
    "plt.xlabel('Signal/Noise Ratio')\n",
    "plt.ylabel('P-value')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Mutual info score, P-values on experiments')\n",
    "plt.show()\n",
    "\n",
    "for i in range(0,4): #Nb points\n",
    "    #rint((sig_to_noise_rate))\n",
    "    #rint(list(means_MI[:,i]))\n",
    "    plt.errorbar(sig_to_noise_rate,list(means_pear[:,i]),yerr=std_pear[:,i],label=str((i+1)*10)+' pts')\n",
    "plt.xlabel('Signal/Noise Ratio')\n",
    "plt.ylabel('P-value')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Pearson correlation, P-values on experiments')\n",
    "plt.()'''\n",
    "        \n",
    "'''plt.matshow(means_MI)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.matshow(means_pear)\n",
    "plt.show()'''\n",
    "\n",
    "'''t_t,prob=stats.ttest_ind(pval_pear[len(pval_pear)-1][0],pval_MI[len(pval_pear)-1][0],equal_var=False)\n",
    "print(t_t,prob)\n",
    "\n",
    "for i in range(len(pval_pear)-1):\n",
    "    print('Sig/Noise : '+str(i*0.05))\n",
    "    t_t,prob=stats.ttest_ind(pval_pear[i][0],pval_MI[i][0],equal_var=False)\n",
    "    print(means_MI[i,0],std_MI[i,0])\n",
    "    print(means_pear[i,0],std_pear[i,0])\n",
    "    print(t_t,prob)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def job_compute_scores(row,res_p,p_val_p,res_MI,p_val_MI):\\n    x=row['X'].split(' ')\\n    y=row['Y'].split(' ')\\n  \\n    sys.stdout.write('row : '+str(row['ID'])\\n    sys.stdout.flush()\\n    if x[0]=='':\\n        x.pop(0)\\n        y.pop(0)\\n    x=[float(i) for i in x]\\n    y=[float(j) for j in y]\\n    r1=test1(x,y)\\n    p1=p_val_test1(x,y)\\n    r2=test2(x,y)\\n    p2=p_val_test2(x,y)\\n    \\n    #Writing results into shared memory\\n    n_id= int(row['ID'])\\n    res_p[n_id]=r1\\n    p_val_p[n_id]=p1\\n    res_MI[n_id]=r2\\n    p_val_MI[n_id]=p2\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def job_compute_scores(row,res_p,p_val_p,res_MI,p_val_MI):\n",
    "    x=row['X'].split(' ')\n",
    "    y=row['Y'].split(' ')\n",
    "  \n",
    "    sys.stdout.write('row : '+str(row['ID'])\n",
    "    sys.stdout.flush()\n",
    "    if x[0]=='':\n",
    "        x.pop(0)\n",
    "        y.pop(0)\n",
    "    x=[float(i) for i in x]\n",
    "    y=[float(j) for j in y]\n",
    "    r1=test1(x,y)\n",
    "    p1=p_val_test1(x,y)\n",
    "    r2=test2(x,y)\n",
    "    p2=p_val_test2(x,y)\n",
    "    \n",
    "    #Writing results into shared memory\n",
    "    n_id= int(row['ID'])\n",
    "    res_p[n_id]=r1\n",
    "    p_val_p[n_id]=p1\n",
    "    res_MI[n_id]=r2\n",
    "    p_val_MI[n_id]=p2'''\n",
    "                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "'''chunked_data=pd.read_csv('linear_dataset.csv',chunksize=10**4)\n",
    "data=pd.DataFrame()\n",
    "for chunk in chunked_data:\n",
    "    data=pd.concat([data,chunk])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"p=Pool(processes=proc)\\nres_p=Array('d',range(number_lines))\\np_val_p=Array('d',range(number_lines))\\nres_MI=Array('d',range(number_lines))\\np_val_MI=Array('d',range(number_lines))\\nidlist=[]\\ncoeff=[]\\nnoise_sig=[]\\nnb_pts=[]\\n\\nfor idx,row in data.iterrows():\\n    p.apply_async(job_compute_scores,(row,res_p,p_val_p,res_MI,p_val_MI))\\n    idlist.append(row['ID'])\\n    coeff.append(row['Coeff'])\\n    nb_pts.append(row['Nb_pts'])\\n    noise_sig.append(row['Noise/Sig'])\\np.close()\\np.join()\\n\\nresult=[]\\nfor i in range(len(idlist)):\\n    result.append([idlist[i],res_p[i],p_val_p[i],res_MI[i],p_val_MI[i],\\n                   coeff[i],nb_pts[i],noise_sig[i]])\\n\\nres_df=pd.DataFrame(result,columns=['ID','Pearson_Correlation','Pearson_p-val',\\n                                    'Mutual_information','MI_p-val',\\n                                    'Coeff','Nb_pts','Noise/Sig'])\\nres_df.to_csv('result_linear_test.csv',index=False)\\n    \""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Main computation loop\n",
    "'''p=Pool(processes=proc)\n",
    "res_p=Array('d',range(number_lines))\n",
    "p_val_p=Array('d',range(number_lines))\n",
    "res_MI=Array('d',range(number_lines))\n",
    "p_val_MI=Array('d',range(number_lines))\n",
    "idlist=[]\n",
    "coeff=[]\n",
    "noise_sig=[]\n",
    "nb_pts=[]\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    p.apply_async(job_compute_scores,(row,res_p,p_val_p,res_MI,p_val_MI))\n",
    "    idlist.append(row['ID'])\n",
    "    coeff.append(row['Coeff'])\n",
    "    nb_pts.append(row['Nb_pts'])\n",
    "    noise_sig.append(row['Noise/Sig'])\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "result=[]\n",
    "for i in range(len(idlist)):\n",
    "    result.append([idlist[i],res_p[i],p_val_p[i],res_MI[i],p_val_MI[i],\n",
    "                   coeff[i],nb_pts[i],noise_sig[i]])\n",
    "\n",
    "res_df=pd.DataFrame(result,columns=['ID','Pearson_Correlation','Pearson_p-val',\n",
    "                                    'Mutual_information','MI_p-val',\n",
    "                                    'Coeff','Nb_pts','Noise/Sig'])\n",
    "res_df.to_csv('result_linear_test.csv',index=False)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
