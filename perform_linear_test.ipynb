{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook perform_linear_test.ipynb to script\n",
      "[NbConvertApp] Writing 3037 bytes to perform_linear_test.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script perform_linear_test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from random import shuffle\n",
    "from multiprocessing import Pool,Array\n",
    "import sys\n",
    "proc=15\n",
    "number_lines=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_variable(var1):   # bin with normalization  \n",
    "    var1=np.std(np.array(var1).astype(np.float))\n",
    "    \n",
    "    if abs(np.std(var1))>0.01:\n",
    "        var1 = (var1 - np.mean(var1))/np.std(var1)\n",
    "    else:\n",
    "        var1 = (var1 - np.mean(var1))\n",
    "    val1 = np.digitize(var1, np.histogram(var1, bins='fd')[1])\n",
    "    print(type(val1))\n",
    "    print((val1).shape())\n",
    "    return val1\n",
    "\n",
    "def p_val_mi(x,y):\n",
    "    count=0.0\n",
    "    iterations=10000\n",
    "    score=metrics.adjusted_mutual_info_score(x,y)\n",
    "    for i in range(iterations):\n",
    "        shuffle(x)\n",
    "        shuffle(y)\n",
    "        if metrics.adjusted_mutual_info_score(x,y)>=score:\n",
    "            count+=1.0\n",
    "    return count/iterations\n",
    "        \n",
    "test1=lambda x,y : stats.pearsonr(np.array(x),np.array(y))[0]\n",
    "p_val_test1=lambda x,y :stats.pearsonr(np.array(x),np.array(y))[1]\n",
    "\n",
    "test2=lambda x,y : metrics.adjusted_mutual_info_score(bin_variable(x),bin_variable(y))\n",
    "p_val_test2= lambda x,y : p_val_mi(bin_variable(x),bin_variable(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def job_compute_scores(row,res_p,p_val_p,res_MI,p_val_MI):\n",
    "    x=row['X'].split(' ')\n",
    "    y=row['Y'].split(' ')\n",
    "  \n",
    "    sys.stdout.write('row : '+str(row['ID'])\n",
    "    sys.stdout.flush()\n",
    "    if x[0]=='':\n",
    "        x.pop(0)\n",
    "        y.pop(0)\n",
    "    x=[float(i) for i in x]\n",
    "    y=[float(j) for j in y]\n",
    "    r1=test1(x,y)\n",
    "    p1=p_val_test1(x,y)\n",
    "    r2=test2(x,y)\n",
    "    p2=p_val_test2(x,y)\n",
    "    \n",
    "    #Writing results into shared memory\n",
    "    n_id= int(row['ID'])\n",
    "    res_p[n_id]=r1\n",
    "    p_val_p[n_id]=p1\n",
    "    res_MI[n_id]=r2\n",
    "    p_val_MI[n_id]=p2\n",
    "                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "chunked_data=pd.read_csv('linear_dataset.csv',chunksize=10**4)\n",
    "data=pd.DataFrame()\n",
    "for chunk in chunked_data:\n",
    "    data=pd.concat([data,chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-33b96e129035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mp_val_MI\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#Main computation loop\n",
    "p=Pool(processes=proc)\n",
    "res_p=Array('d',range(number_lines))\n",
    "p_val_p=Array('d',range(number_lines))\n",
    "res_MI=Array('d',range(number_lines))\n",
    "p_val_MI=Array('d',range(number_lines))\n",
    "idlist=[]\n",
    "coeff=[]\n",
    "noise_sig=[]\n",
    "nb_pts=[]\n",
    "\n",
    "for idx,row in data.iterrows():\n",
    "    p.apply_async(job_compute_scores,(row,res_p,p_val_p,res_MI,p_val_MI))\n",
    "    idlist.append(row['ID'])\n",
    "    coeff.append(row['Coeff'])\n",
    "    nb_pts.append(row['Nb_pts'])\n",
    "    noise_sig.append(row['Noise/Sig'])\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "result=[]\n",
    "for i in range(len(idlist)):\n",
    "    result.append([idlist[i],res_p[i],p_val_p[i],res_MI[i],p_val_MI[i],\n",
    "                   coeff[i],nb_pts[i],noise_sig[i]])\n",
    "\n",
    "res_df=pd.DataFrame(result,columns=['ID','Pearson_Correlation','Pearson_p-val',\n",
    "                                    'Mutual_information','MI_p-val',\n",
    "                                    'Coeff','Nb_pts','Noise/Sig'])\n",
    "res_df.to_csv('result_linear_test.csv',index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
